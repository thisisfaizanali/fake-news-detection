# Fake News Detection ğŸ“°ğŸ”

Welcome to the Fake News Detection project! ğŸš€ This is a final-year project that uses machine learning to classify news as real âœ… or fake âŒ based on text input, uploaded videos, or YouTube URLs. Built with Streamlit for a slick UI, Whisper for audio transcription, and scikit-learn for powerful ML models, this app is your go-to tool for sniffing out fake news! ğŸ•µï¸â€â™‚ï¸

## Features

Text Input ğŸ“: Type in news text and get instant classification.
Video Upload ğŸ¥: Upload MP4 videos, extract audio, transcribe it, and classify the content.
YouTube URL ğŸŒ: Paste a YouTube link to download, transcribe, and classify the videoâ€™s content.
Model Selection ğŸ¤–: Choose from four ML models:
Logistic Regression
Decision Tree
Random Forest
K-Nearest Neighbors (KNN)

Explainability ğŸ”: See the top 5 words/phrases influencing the classification (for Logistic Regression and Random Forest).
User-Friendly UI ğŸ¨: Built with Streamlit for a seamless experience.

## Prerequisites ğŸ› ï¸

To run this project, youâ€™ll need:

Python 3.8+ ğŸ
A virtual environment (highly recommended) ğŸŒ
FFmpeg installed for video processing (see FFmpeg Installation) ğŸ“¼
The Full dataset.csv file for training models ğŸ“Š
Pre-trained model pickle files (e.g., LogisticRegressionmodel.pkl) ğŸ“¦

## Installation ğŸ“¦

Clone the Repository:

```
git clone https://github.com/thisisfaizanali/fake-news-detection.git
cd fake-news-detection
```

## Set Up a Virtual Environment:

```
python -m venv venv
source venv/bin/activate # On Windows: venv\Scripts\activate
```

## Install Dependencies:

```
pip install -r requirements.txt
```

## Add Dataset and Models:

Place Full dataset.csv in the project root (not included in Git due to size).
Add pre-trained pickle files (e.g., LogisticRegressionmodel.pkl, etc.) to the project root. These are not in the repo but can be regenerated using modelo.ipynb or obtained from the project owner.

## Run the App:

```
streamlit run app.py
```

## Usage ğŸš€

## Launch the App:

Run streamlit run app.py to open the Streamlit interface in your browser.

## Choose Input Type:

Select Text ğŸ“, Video ğŸ¥, or YouTube URL ğŸŒ from the sidebar.

## Pick a Model:

Choose a model (Logistic Regression, Decision Tree, Random Forest, or KNN) from the sidebar.

## Classify News:

Text: Enter news text and click "Classify".
Video: Upload an MP4 file to transcribe and classify.
YouTube URL: Paste a YouTube link to download, transcribe, and classify.

## View Results:

See if the news is Real âœ… or Fake âŒ, with probability scores.
For Logistic Regression and Random Forest, check the top 5 influential words/phrases.

## Project Structure ğŸ“‚

fake-news-detection/
â”œâ”€â”€ app.py                # Main Streamlit app for classification ğŸŒŸ
â”œâ”€â”€ streamlitmain.py      # Handles video upload & transcription ğŸ¥
â”œâ”€â”€ yt_down_main.py       # Downloads & transcribes YouTube videos ğŸŒ
â”œâ”€â”€ modelo.ipynb          # Jupyter notebook for training ML models ğŸ““
â”œâ”€â”€ .gitignore            # Specifies files/folders to ignore in Git ğŸš«
â”œâ”€â”€ README.md             # You're reading it! ğŸ“–
â”œâ”€â”€ requirements.txt      # Python dependencies ğŸ“‹
â”œâ”€â”€ Full dataset.csv      # Dataset (excluded from Git repo) ğŸ“Š
â””â”€â”€ *.pkl                 # Pre-trained ML model files (excluded) ğŸ“¦


## Dataset ğŸ“Š

File: Full dataset.csv
Description: Contains news articles labeled as 0 (Fake) or 1 (Real).
Note: Excluded from the repository due to size. Contact the project owner or use a similar dataset. You can also regenerate it if you have access to the original sources.

## Model Training ğŸ§ 

Notebook: modelo.ipynb
Purpose: Loads and preprocesses the dataset, trains four ML models, and saves them as pickle files (commented out in the notebook).
Steps:
Run modelo.ipynb to preprocess Full dataset.csv.
Uncomment joblib.dump lines to save models as .pkl files.
Use these models in app.py for classification.

## Dependencies ğŸ“‹

See requirements.txt for the full list. Key packages include:

streamlit ğŸ¨: For the web interface
pandas ğŸ“Š: For data handling
pytube ğŸŒ: For YouTube video downloads
moviepy ğŸ¥: For video/audio processing
whisper ğŸ™ï¸: For audio transcription
scikit-learn ğŸ¤–: For ML models
numpy ğŸ”¢: For numerical operations
joblib ğŸ“¦: For model persistence

Install them with:
pip install -r requirements.txt

## FFmpeg Installation ğŸ–¥ï¸

FFmpeg is required for video/audio processing. Install it based on your OS:

Windows:
Download FFmpeg from ffmpeg.org.
Extract the archive and add the bin folder to your system PATH.
Verify with ffmpeg -version in your terminal.

MacOS:

```
brew install ffmpeg
```

Linux:

```
sudo apt-get install ffmpeg # Ubuntu/Debian
sudo yum install ffmpeg # CentOS/RHEL
```

## Notes âš ï¸

Pickle Files: Pre-trained models (e.g., LogisticRegressionmodel.pkl) are not in the repo due to size. Regenerate them with modelo.ipynb or contact the project owner.
YouTube Downloads: Requires a stable internet connection and compliance with YouTubeâ€™s terms of service.
Whisper Model: Uses the base model. Ensure sufficient memory for video processing.
Virtual Environment: Strongly recommended to avoid dependency conflicts (see Installation).

## Contributing ğŸ¤

Got ideas? ğŸ’¡ Fork the repo, make changes, and submit a pull request! Follow PEP 8 guidelines and add clear comments. Letâ€™s make this project even better! ğŸ™Œ

## Acknowledgments ğŸ™

Built as a final-year project to combat fake news ğŸ“°.
Big thanks to the open-source communities behind Streamlit, Whisper, PyTube, and scikit-learn! â¤ï¸
Special shoutout to my friend who helped with the ML bits! ğŸ¤—

Happy classifying! ğŸ‰
